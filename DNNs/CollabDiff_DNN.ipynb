{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "ogoJf12DbAmR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "52Iqg-m4KCJh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gdown\n",
        "from pathlib import PosixPath\n",
        "# CollabDiff\n",
        "!gdown --id 1GpGvkxQ7leXqCnfnEAsgY_DXFnJwIbO4 -c\n",
        "!unzip -q -n CollabDiff.zip\n",
        "image_path = PosixPath(\"content/drive/MyDrive/GenAI/CollabDiff\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I0NOIqtqLqUs",
        "outputId": "8ca1d633-8e18-423b-91b2-a2fd527ea526"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gdown in /usr/local/lib/python3.10/dist-packages (5.2.0)\n",
            "Requirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from gdown) (4.12.3)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from gdown) (3.16.1)\n",
            "Requirement already satisfied: requests[socks] in /usr/local/lib/python3.10/dist-packages (from gdown) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from gdown) (4.66.6)\n",
            "Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->gdown) (2.6)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (2024.8.30)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.10/dist-packages (from requests[socks]->gdown) (1.7.1)\n",
            "/usr/local/lib/python3.10/dist-packages/gdown/__main__.py:140: FutureWarning: Option `--id` was deprecated in version 4.3.1 and will be removed in 5.0. You don't need to pass it anymore to use a file ID.\n",
            "  warnings.warn(\n",
            "Downloading...\n",
            "From (original): https://drive.google.com/uc?id=1GpGvkxQ7leXqCnfnEAsgY_DXFnJwIbO4\n",
            "From (redirected): https://drive.google.com/uc?id=1GpGvkxQ7leXqCnfnEAsgY_DXFnJwIbO4&confirm=t&uuid=41f62b3e-9168-4f65-92e0-605f176a2b62\n",
            "To: /content/CollabDiff.zip\n",
            "100% 354M/354M [00:06<00:00, 58.6MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(42)\n",
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "id": "2KMyH6tmLAXt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90840e9d-906c-4232-afcc-e4e2c46eb241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x795557653ef0>"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hyfoaN1gKtYV"
      },
      "outputs": [],
      "source": [
        "def get_req_set(path):\n",
        "  df = pd.read_csv(path)\n",
        "  features_df = df['features'].str.strip('[]').str.split(',', expand=True)\n",
        "  features_df = features_df.astype(float)\n",
        "  features_df.columns = [f'feature_{i}' for i in range(features_df.shape[1])]\n",
        "  df_expanded = pd.concat([features_df, df['label']], axis=1)\n",
        "  X = df_expanded.drop(columns=['label'])\n",
        "  y = df_expanded['label']\n",
        "  X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
        "  y_tensor = torch.tensor(y.values, dtype=torch.long)\n",
        "  dataset = TensorDataset(X_tensor, y_tensor)\n",
        "  print(len(dataset))\n",
        "  temp_loader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
        "  return temp_loader"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#JPEGS taken from all folders"
      ],
      "metadata": {
        "id": "NAIPJzdYZ4e0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_loader = get_req_set('/content/train_features.csv')\n",
        "val_loader = get_req_set('/content/val_features.csv')\n",
        "test_loader = get_req_set('/content/test_features.csv')"
      ],
      "metadata": {
        "id": "D_g_5JphMRoW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1f1f688b-63a4-410a-b331-9620a9121acf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1400\n",
            "200\n",
            "400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DNN(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim_1, hidden_dim_2, output_dim, dropout_prob=0.2):\n",
        "        super(DNN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, hidden_dim_1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.dropout1 = nn.Dropout(p=dropout_prob)\n",
        "        self.fc2 = nn.Linear(hidden_dim_1, hidden_dim_2)\n",
        "        self.dropout2 = nn.Dropout(p=dropout_prob)\n",
        "        self.fc3 = nn.Linear(hidden_dim_2, output_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return x\n"
      ],
      "metadata": {
        "id": "ShQZN8S9M1f0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Updated loop with four validation datasets and additional metrics\n",
        "input_dim = 768      # Number of features in the produced dataset\n",
        "hidden_dim_1 = 128\n",
        "hidden_dim_2 = 256\n",
        "output_dim = 2 # Number of classes -- 2\n",
        "model = DNN(input_dim, hidden_dim_1, hidden_dim_2, output_dim)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-5)\n",
        "train_losses, test_losses = [], []\n",
        "train_accuracies, test_accuracies = [], []\n",
        "num_epochs = 10\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    correct_predictions = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    for batch_X, batch_y in train_loader:\n",
        "        outputs = model(batch_X)\n",
        "        loss = criterion(outputs, batch_y)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        running_loss += loss.item()\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        correct_predictions += (predicted == batch_y).sum().item()\n",
        "        total_samples += batch_y.size(0)\n",
        "\n",
        "    # Calculate train loss and metrics\n",
        "    train_loss = running_loss / len(train_loader)\n",
        "    train_accuracy = correct_predictions / total_samples * 100\n",
        "    train_losses.append(train_loss)\n",
        "    train_accuracies.append(train_accuracy)\n",
        "\n",
        "    # Evaluate on train data\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        y_true_train = []\n",
        "        y_pred_train = []\n",
        "        for batch_X, batch_y in train_loader:\n",
        "            outputs = model(batch_X)\n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            y_true_train.extend(batch_y.cpu().numpy())\n",
        "            y_pred_train.extend(predicted.cpu().numpy())\n",
        "\n",
        "    # Calculate train metrics\n",
        "    train_precision = precision_score(y_true_train, y_pred_train, average='binary')\n",
        "    train_recall = recall_score(y_true_train, y_pred_train, average='binary')\n",
        "    train_f1 = f1_score(y_true_train, y_pred_train, average='binary')\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{num_epochs}], \"\n",
        "          f\"Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, \"\n",
        "          f\"Train Precision: {train_precision:.2f}, Train Recall: {train_recall:.2f}, Train F1: {train_f1:.2f}\")\n",
        "\n",
        "    # Validation loaders and names\n",
        "    val_loaders = [val_loader, test_loader]\n",
        "    val_names = ['Validation','Testing']\n",
        "\n",
        "    # Evaluate on each validation set\n",
        "    for val_loader, val_name in zip(val_loaders, val_names):\n",
        "        y_true_val = []\n",
        "        y_pred_val = []\n",
        "        val_loss = 0.0\n",
        "\n",
        "        with torch.no_grad():\n",
        "            for batch_X, batch_y in val_loader:\n",
        "                outputs = model(batch_X)\n",
        "                loss = criterion(outputs, batch_y)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                _, predicted = torch.max(outputs, 1)\n",
        "                y_true_val.extend(batch_y.cpu().numpy())\n",
        "                y_pred_val.extend(predicted.cpu().numpy())\n",
        "\n",
        "        # Calculate metrics for each validation set\n",
        "        val_loss /= len(val_loader)\n",
        "        val_accuracy = accuracy_score(y_true_val, y_pred_val) * 100\n",
        "        val_precision = precision_score(y_true_val, y_pred_val, average='binary')\n",
        "        val_recall = recall_score(y_true_val, y_pred_val, average='binary')\n",
        "        val_f1 = f1_score(y_true_val, y_pred_val, average='binary')\n",
        "\n",
        "        print(f\"{val_name} - \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.2f}%, \"\n",
        "              f\"Val Precision: {val_precision:.2f}, Val Recall: {val_recall:.2f}, Val F1: {val_f1:.2f}\")\n",
        "\n",
        "    print(\"------------------------------------------------\")"
      ],
      "metadata": {
        "id": "e5dcLBLMQp_Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8194cbc9-a1a7-450d-ae73-54f98349d273"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/10], Train Loss: 0.2822, Train Accuracy: 90.93%, Train Precision: 1.00, Train Recall: 1.00, Train F1: 1.00\n",
            "Validation - Val Loss: 0.0060, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "Testing - Val Loss: 0.0039, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "------------------------------------------------\n",
            "Epoch [2/10], Train Loss: 0.0022, Train Accuracy: 100.00%, Train Precision: 1.00, Train Recall: 1.00, Train F1: 1.00\n",
            "Validation - Val Loss: 0.0020, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "Testing - Val Loss: 0.0022, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "------------------------------------------------\n",
            "Epoch [3/10], Train Loss: 0.0006, Train Accuracy: 100.00%, Train Precision: 1.00, Train Recall: 1.00, Train F1: 1.00\n",
            "Validation - Val Loss: 0.0013, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "Testing - Val Loss: 0.0013, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "------------------------------------------------\n",
            "Epoch [4/10], Train Loss: 0.0006, Train Accuracy: 100.00%, Train Precision: 1.00, Train Recall: 1.00, Train F1: 1.00\n",
            "Validation - Val Loss: 0.0007, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "Testing - Val Loss: 0.0007, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "------------------------------------------------\n",
            "Epoch [5/10], Train Loss: 0.0004, Train Accuracy: 100.00%, Train Precision: 1.00, Train Recall: 1.00, Train F1: 1.00\n",
            "Validation - Val Loss: 0.0008, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "Testing - Val Loss: 0.0008, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "------------------------------------------------\n",
            "Epoch [6/10], Train Loss: 0.0002, Train Accuracy: 100.00%, Train Precision: 1.00, Train Recall: 1.00, Train F1: 1.00\n",
            "Validation - Val Loss: 0.0012, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "Testing - Val Loss: 0.0012, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "------------------------------------------------\n",
            "Epoch [7/10], Train Loss: 0.0002, Train Accuracy: 100.00%, Train Precision: 1.00, Train Recall: 1.00, Train F1: 1.00\n",
            "Validation - Val Loss: 0.0013, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "Testing - Val Loss: 0.0013, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "------------------------------------------------\n",
            "Epoch [8/10], Train Loss: 0.0001, Train Accuracy: 100.00%, Train Precision: 1.00, Train Recall: 1.00, Train F1: 1.00\n",
            "Validation - Val Loss: 0.0009, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "Testing - Val Loss: 0.0006, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "------------------------------------------------\n",
            "Epoch [9/10], Train Loss: 0.0001, Train Accuracy: 100.00%, Train Precision: 1.00, Train Recall: 1.00, Train F1: 1.00\n",
            "Validation - Val Loss: 0.0008, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "Testing - Val Loss: 0.0005, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "------------------------------------------------\n",
            "Epoch [10/10], Train Loss: 0.0001, Train Accuracy: 100.00%, Train Precision: 1.00, Train Recall: 1.00, Train F1: 1.00\n",
            "Validation - Val Loss: 0.0005, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "Testing - Val Loss: 0.0005, Val Accuracy: 100.00%, Val Precision: 1.00, Val Recall: 1.00, Val F1: 1.00\n",
            "------------------------------------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "3LVLlmTrKVO5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}